# 1.神经网络
前置知识：线性回归算法（一）  

主要内容：神经元、感知器、输入层、隐藏层、输出层、激活函数、正向传播、反向传播、随机梯度下降法、全连接神经网络  

推荐资料：[神经网络](https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/10.%20Neural%20Network)  
　　　　　[零基础入门深度学习(1) - 感知器](https://www.zybuluo.com/hanbingtao/note/433855)  
　　　　　[零基础入门深度学习(3) - 神经网络和反向传播算法](https://www.zybuluo.com/hanbingtao/note/476663)  
　　　　　[3. 线性神经网络](https://zh-v2.d2l.ai/chapter_linear-networks/index.html)  
　　　　　[4. 多层感知机](https://www.zybuluo.com/hanbingtao/note/433855)  
# 2.卷积神经网络
前置知识：神经网络  

主要内容：输入层、卷积计算层、激励层、池化层、全连接层  

推荐资料：[卷积神经网络](https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/11.%20CNN)  
　　　　　[YJango的卷积神经网络——介绍](https://zhuanlan.zhihu.com/p/27642620)  
　　　　　[零基础入门深度学习(4) - 卷积神经网络](https://www.zybuluo.com/hanbingtao/note/476663)  
　　　　　[6. 卷积神经网络](https://zh-v2.d2l.ai/chapter_convolutional-neural-networks/index.html)
# 3.循环神经网络
前置知识：神经网络  

主要内容：循环神经网络、双向循环神经网络、深度循环神经网络、BPTT算法  

推荐资料：[循环神经网络](https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.%20RNN#2-%E5%85%B6%E5%AE%83%E7%B1%BB%E5%9E%8B%E7%9A%84rnn)  
　　　　　[YJango的循环神经网络——介绍](https://zhuanlan.zhihu.com/p/24720659)  
　　　　　[零基础入门深度学习(5) - 循环神经网络](https://zybuluo.com/hanbingtao/note/541458)  
　　　　　[8. 循环神经网络](https://zh-v2.d2l.ai/chapter_recurrent-neural-networks/index.html)
# 4.现代循环神经网络
前置知识：循环神经网络  

主要内容：门控循环单元、长短期记忆网络、编码器-解码器架构、序列到序列模型  

推荐资料：[门控循环单元](https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.1%20GRU)  
　　　　　[长短期记忆](https://github.com/NLP-LOVE/ML-NLP/tree/master/Deep%20Learning/12.2%20LSTM)  
　　　　　[零基础入门深度学习(6) - 长短时记忆网络(LSTM)](https://zybuluo.com/hanbingtao/note/581764)  
　　　　　[序列到序列模型](https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.5%20seq2seq)  
　　　　　[9. 现代循环神经网络](https://zh-v2.d2l.ai/chapter_recurrent-modern/index.html)
# *5.递归神经网络*
前置知识：循环神经网络  

主要内容：递归神经网络、前向计算、训练  

推荐资料：[零基础入门深度学习(7) - 递归神经网络](https://zybuluo.com/hanbingtao/note/626300)
# 6.注意力机制
前置知识：现代循环神经网络  

主要内容：注意力提示、Nadaraya-Watson 核回归、注意力评分函数、Bahdanau 注意力、多头注意力、自注意力和位置编码、Transformer

推荐资料：[注意力机制](https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.6%20Attention)  
　　　　　[Transformer模型](https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.7%20Transformer)  
　　　　　[10. 注意力机制](https://zh-v2.d2l.ai/chapter_attention-mechanisms/index.html)  
　　　　　[Attention Is All You Need](https://arxiv.org/pdf/1706.03762)
# 7.自然语言处理
前置知识：卷积神经网络、注意力机制  

主要内容：词嵌入、子词嵌入、全局向量词嵌入、textRNN、textCNN、序列到序列模型、BERT、XLNet  

推荐资料：[【自然语言处理笔记】（一）N-gram语言模型与神经网络语言模型](https://zhuanlan.zhihu.com/p/22090476746)  
　　　　　[一起入门语言模型(Language Models)](https://zhuanlan.zhihu.com/p/32292060)  
　　　　　[自然语言处理](https://github.com/NLP-LOVE/ML-NLP/tree/master/NLP/16.%20NLP)  
　　　　　[14. 自然语言处理：预训练](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/index.html)
# 8.ChatGPT
前置知识：自然语言处理  

主要内容：GPT、Bert、GPT-2、GPT-3、InstructGPT、ChatGPT  

推荐资料：[一文读懂ChatGPT的前世今生（文末附相关论文下载）](https://zhuanlan.zhihu.com/p/607581437)  
# 9.DeepSeek、Kimi、o1
前置知识：ChatGPT  

主要内容：DeepSeek LLM、DeepSeekMoE、DeepSeek-V3、DeepSeek-R1、Kimi-k1.5、Kimi-k1.6、o1  

推荐资料：[deepseek各个版本及论文](https://blog.csdn.net/yiqi1943/article/details/145370544)  
　　　　　[【论文解读】Kimi-k1.5：无需复杂搜索，Long Context + RL就能实现复杂推理](https://zhuanlan.zhihu.com/p/19612718816)  
　　　　　[Native Sparse Attention: Hardware-Aligned and Natively
 Trainable Sparse Attention](https://arxiv.org/pdf/2502.11089)
# 10.大模型研究
前置知识：ChatGPT、*DeepSeek、Kimi、o1*  

主要内容：Prompt、Let's think step by step、In-Context Learning、大模型幻觉、LLM后预训练方法、大模型微调评测、混合小模型、分布式注意力、MoE-Mamba、大模型微调方法、线性注意力、LORA链、实体关系提取  

推荐资料：[关于 ChatGPT 必看的 10 篇论文](https://blog.csdn.net/u010280923/article/details/128969774)  
　　　　　[LLM 大幅提升结果的准确性：Let's think step by step -- 来自论文《Large Language Models are Zero-Shot Reasoners》](https://zhuanlan.zhihu.com/p/652206747)  
　　　　　[2024最新！| 分享10篇优秀论文，涉及大模型微调、Transformer、混合模型等热门话题](https://zhuanlan.zhihu.com/p/677201033)  
# 11.多模态大模型
前置知识：ChatGPT、*计算机视觉*  

推荐资料：*[一文看完多模态：从视觉表征到多模态大模型](https://zhuanlan.zhihu.com/p/684472814)*  
　　　　　[论文分享|MLLMs中多种模态(图像/视频/音频/语音)的tokenizer梳理](https://blog.csdn.net/weixin_45783724/article/details/141170597)  
　　　　　[GPT-4论文](https://arxiv.org/pdf/2303.08774)  
# *12.大模型应用开发*
前置知识：*大模型研究*、*多模态大模型*、*强化学习*  

主要内容：Prompt工程、embeddings、向量数据库、RAG、Function Calling、跨模型协作、智能体、Fine-tuning、大模型优化
