# 1.LeNet
前置知识：2.理论篇-卷积神经网络、3.编程篇-计算机视觉  

推荐资料：[6.6.卷积神经网络（LeNet）](https://zh-v2.d2l.ai/chapter_convolutional-neural-networks/lenet.html)  
# 2.AlexNet
前置知识：LeNet、2.理论篇-现代卷积神经网络  

推荐资料：[7.1.深度卷积神经网络（AlexNet）](https://zh-v2.d2l.ai/chapter_convolutional-modern/alexnet.html)  
# 3.VGG
前置知识：AlexNet  

推荐资料：[7.2.使用块的网络（VGG）](https://zh-v2.d2l.ai/chapter_convolutional-modern/vgg.html)
# 4.NiN
前置知识：AlexNet  

推荐资料：[7.3.网络中的网络（NiN）](https://zh-v2.d2l.ai/chapter_convolutional-modern/nin.html)
# 5.GoogLeNet
前置知识：NiN

推荐资料：[7.4. 含并行连结的网络（GoogLeNet）](https://zh-v2.d2l.ai/chapter_convolutional-modern/googlenet.html)  
# 6.ResNet
前置知识：NiN、2.理论篇-计算机视觉  

推荐资料：[7.6.残差网络（ResNet）](https://zh-v2.d2l.ai/chapter_convolutional-modern/resnet.html)
# 7.DenseNet
前置知识：ResNet  

推荐资料：[7.7. 稠密连接网络（DenseNet）](https://zh-v2.d2l.ai/chapter_convolutional-modern/densenet.html)
# 8.SSD
前置知识：2.理论篇-计算机视觉

推荐资料：[13.7. 单发多框检测（SSD）](https://zh-v2.d2l.ai/chapter_computer-vision/ssd.html)
# 9.R-CNN
前置知识：SSD  

源码：[R-CNN](https://github.com/rbgirshick/rcnn)  
# 10.SPP Net
前置知识：R-CNN

推荐资料：[SPP net详解](https://github.com/ShaoQiBNU/CV-SPPnet)  
# 11.Fast R-CNN
前置知识：SPP Net  

源码：[Fast R-CNN](https://github.com/rbgirshick/fast-rcnn)   
# 12.Faster R-CNN
前置知识：Fast R-CNN  

源码：[Faster R-CNN](https://github.com/rbgirshick/py-faster-rcnn)  
# 13.Mask R-CNN  
前置知识：Faster R-CNN

源码：[Mask R-CNN](https://github.com/matterport/Mask_RCNN)
# 14.YOLO
前置知识：Faster R-CNN

源码：[YOLOv3](https://pjreddie.com/darknet/yolo/)  
　　　[YOLOv4](https://github.com/AlexeyAB/darknet)  
　　　[YOLOv5](https://github.com/ultralytics/yolov5)  
　　　[YOLO X](https://github.com/Megvii-BaseDetection/YOLOX?tab=readme-ov-file)  
　　　[YOLOv6](https://github.com/meituan/YOLOv6/)  
　　　[YOLOv7](https://github.com/WongKinYiu/yolov7)  
　　　[YOLOv9](https://github.com/WongKinYiu/yolov9)  
　　　[YOLOv10](https://github.com/THU-MIG/yolov10)  
# 15.视觉Transformer
前置知识：2.理论篇-注意力机制、*YOLO*  

主要内容：Vision Transformer、*YOLOv11*、*YOLOv12*

源码：[Vision Transformer](https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/vision_transformer.py)  
　　　*[YOLOv11](https://github.com/ultralytics/ultralytics)*  
　　　*[YOLOv12](https://github.com/sunsmarterjie/yolov12)*
# 16.segment anything
前置知识：视觉Transformer  

源码：[segment anything](https://github.com/facebookresearch/segment-anything)  
# 17.recognize anything
前置知识：视觉Transformer  

源码：[recognize anything](https://github.com/xinyu1205/recognize-anything)  
# 18.track anything  
前置知识:视觉Tranformer  

源码：[track anything](https://github.com/gaomingqi/track-anything)
